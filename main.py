from fastapi import FastAPI, UploadFile, File, Query, Form
from pydantic import BaseModel
from fastapi.responses import JSONResponse
from typing import List, Optional, Union
from openai import OpenAI
from dotenv import load_dotenv
import json
from grad.analyzer import analyze_graduation_pdf
import numpy as np
from typing import Dict, Any
# í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
load_dotenv()
client = OpenAI()
user_interest_memory = []

curriculum = []

import os

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")

for filename in [
    "cse_courses.json",
    "sw_courses.json",
    "ai_courses.json"
]:
    with open(os.path.join(DATA_DIR, filename), "r", encoding="utf-8") as f:
        curriculum += json.load(f)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()

# ìš”ì²­ ëª¨ë¸
class RecommendRequest(BaseModel):
    keyword: str
    add_info: str

# ì¶”ì²œ í•­ëª© ëª¨ë¸
class RecommendationItem(BaseModel):
    title: str
    description: str

# ì‘ë‹µ ëª¨ë¸
class RecommendResponse(BaseModel):
    keyword: str
    add_info: str
    ai_response: str  # ë¬¸ìì—´ ì‘ë‹µìœ¼ë¡œ êµ¬ì„±

# ì—ëŸ¬ ì‘ë‹µ ëª¨ë¸
class ErrorResponse(BaseModel):
    error: str
    raw_text: Optional[str] = None
    warning: Optional[str] = None

class ChatRequest(BaseModel):
    question: str

class ChatResponse(BaseModel):
    question: str
    ai_add_response: str

class TimetableResponseDto(BaseModel):
    imageUrl: str
##### ê³¼ëª© ì¶”ì²œ #####
@app.post("/recommend", response_model=Union[RecommendResponse, ErrorResponse])
async def recommend(request: RecommendRequest):
    keyword = request.keyword.lower()

    # ê´€ë ¨ í‚¤ì›Œë“œ ê³¼ëª© í•„í„°ë§
    related = [c for c in curriculum if keyword in [k.lower() for k in c.get("keywords", [])]]
    samples = related[:5] if related else curriculum[:5]

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    context_text = "\n".join([
        f"- {c['name']} ({c['category']}, {c['credit']}í•™ì ): {c.get('description', 'ì„¤ëª… ì—†ìŒ')}"
        for c in samples
    ])

    prompt = f"""
    ë„ˆëŠ” ëŒ€í•™ìƒì—ê²Œ ê³¼ëª©ì„ ì¶”ì²œí•´ì£¼ëŠ” AI ì¡°êµì•¼.
    ì•„ë˜ ì‚¬ìš©ì ì •ë³´ì™€ ê³¼ëª© ëª©ë¡ì„ ì°¸ê³ í•´ì„œ ë°˜ë“œì‹œ ê·¸ ëª©ë¡ ì•ˆì—ì„œë§Œ 3ê°œì˜ ê³¼ëª©ì„ ì¶”ì²œí•´ì¤˜.
    ëª©ë¡ì— ì—†ëŠ” ê³¼ëª©ì€ ì ˆëŒ€ ì¶”ì²œí•˜ë©´ ì•ˆ ë¼.
    ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ, ë‚´ìš©ì€ ëª¨ë‘ í•œêµ­ì–´ë¡œ ì‘ì„±í•´:

    {{
    "recommendations": [
        {{
        "title": "ê³¼ëª©ëª…",
        "description": "ì„¤ëª…"
        }},
        ...
    ]
    }}

    ğŸ” ê´€ì‹¬ ë¶„ì•¼: {request.keyword}
    â„¹ï¸ ì¶”ê°€ ì •ë³´: {request.add_info}
    ê³¼ëª© ëª©ë¡:{context_text}
    """

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” AI ì¡°êµì•¼. ë°˜ë“œì‹œ JSONë§Œìœ¼ë¡œ ë‹µë³€í•´."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2
        )

        result_raw = response.choices[0].message.content.strip()
        result_json = json.loads(result_raw)
        recommendations = result_json.get("recommendations", [])

        # ğŸ“Œ ê´€ì‹¬ì‚¬ ì €ì¥
        user_interest_memory.append({
            "keyword": request.keyword,
            "recommendations": recommendations
        })

        formatted_response = "\n".join([
            f"{i+1}. {r['title']} - {r['description']}" for i, r in enumerate(recommendations)
        ])

        return RecommendResponse(
            keyword=request.keyword,
            add_info=request.add_info,
            ai_response=formatted_response
        )

    except json.JSONDecodeError:
        return ErrorResponse(
            error="JSON íŒŒì‹± ì‹¤íŒ¨",
            raw_text=result_raw,
            warning="AI ì‘ë‹µì„ JSONìœ¼ë¡œ ë³€í™˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        )
    except Exception as e:
        return ErrorResponse(error=str(e))



##### ì§ˆì˜ì‘ë‹µ #####
conversation_history = []

@app.post("/chat", response_model=ChatResponse)
async def chat(req: ChatRequest):
    question = req.question.strip()

    # ê³¼ëª© ìš”ì•½
    summarized = "\n".join([
        f"[{c['code']}] {c['name']} | {c['category']}, {c['credit']}í•™ì , {c['year']}í•™ë…„ | ì„ ìˆ˜ê³¼ëª©: {c['prerequisite'] or 'ì—†ìŒ'}"
        for c in curriculum[:100]
    ])

    # ğŸ“Œ ì´ì „ ì¶”ì²œ ì´ë ¥ ìš”ì•½
    interest_summary = "\n".join([
        f"- ê´€ì‹¬ í‚¤ì›Œë“œ: {m['keyword']} â†’ ì¶”ì²œ ê³¼ëª©: {', '.join([r['title'] for r in m['recommendations']])}"
        for m in user_interest_memory
    ]) or "ì—†ìŒ"

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = f"""
    ë„ˆëŠ” ê²½í¬ëŒ€ ì»´í“¨í„°ê³µí•™ê³¼ GPT ì¡°êµì•¼.
    í•™ìƒì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì»¤ë¦¬í˜ëŸ¼ ê¸°ë°˜ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µí•´ì¤˜.

    ğŸ“Œ ì´ ì‚¬ìš©ìê°€ ë¬¼ì–´ë³¸ ë‚´ìš©ë“¤ì„ ê¸°ì–µí•´ì¤˜:
    {interest_summary}

    ê³¼ëª© ì¶”ì²œì´ í•„ìš”í•  ë• ë°˜ë“œì‹œ ì•„ë˜ ê³¼ëª© ëª©ë¡ ì¤‘ì—ì„œë§Œ ê³¨ë¼.
    ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì •ë³´ëŠ” "ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ì •í™•íˆ ë§í•´.
    ì ˆëŒ€ë¡œ ì˜ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆ. ëª¨ë“  ë¬¸ì¥ì€ ë°˜ë“œì‹œ **í•œêµ­ì–´ë¡œë§Œ** ì‘ì„±í•´.
    """

    conversation_history.append({"role": "user", "content": question})

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": summarized}
            ] + conversation_history,
            temperature=0.4
        )

        reply = response.choices[0].message.content.strip()
        conversation_history.append({"role": "assistant", "content": reply})

        return ChatResponse(
            question=question,
            ai_add_response=reply
        )

    except Exception as e:
        return JSONResponse(
            content={"error": str(e)},
            status_code=500
        )


import os
import shutil

class AnalyzePdfResponse(BaseModel):
    responseData: Dict[str, Any]

@app.post("/analyze-pdf", response_model=AnalyzePdfResponse)
async def analyze_pdf(
    file: UploadFile = File(..., description="ì¡¸ì—… ì§„ë‹¨í‘œ PDF íŒŒì¼"),
    department: str = Form(..., description="í•™ê³¼ëª…"),
    studentId: str = Form(..., description="í•™ë²ˆ")
):
    try:
        # # 1. íŒŒì¼ í˜•ì‹ í™•ì¸
        # if file.content_type != "application/pdf":
        #     return AnalyzePdfResponse(responseData={
        #         "error": "PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
        #         "fileName": file.filename
        #     })

        # 2. íŒŒì¼ ë‚´ìš© ì½ê¸°
        content = await file.read()

        # 3. ì¡¸ì—… ì§„ë‹¨ ì‹¤í–‰
        result = await analyze_graduation_pdf(content, department, studentId)

        # 4. ë¶„ì„ ê²°ê³¼ ê°ì‹¸ê¸°
        if isinstance(result, dict):
            analysis_result = result
        else:
            analysis_result = {"result": result}

        # 5. ê³µí†µ ë©”íƒ€ ì •ë³´ + ë¶„ì„ ê²°ê³¼ í¬í•¨
        return AnalyzePdfResponse(responseData={
            # "studentId": studentId,
            # "department": department,
            # "fileName": file.filename,
            # "message": "FastAPI ì—…ë¡œë“œ ë° ì¡¸ì—… ì§„ë‹¨ ì„±ê³µ âœ…",
            "analysis": analysis_result
        })

    except Exception as e:
        return AnalyzePdfResponse(responseData={
            "error": f"ì„œë²„ ì˜¤ë¥˜: {str(e)}"
        })
##### ê³µê°• ì‹œê°„í‘œ #####

import cv2
import numpy as np
import pytesseract
import re
import os
from fastapi import FastAPI, UploadFile, File
from fastapi.responses import FileResponse
from tempfile import NamedTemporaryFile
pytesseract.pytesseract.tesseract_cmd = "/opt/homebrew/bin/tesseract"

# í…ìŠ¤íŠ¸ ì¸ì‹ í›„ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
def preprocess_and_resize(img):
    large = cv2.resize(img, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_CUBIC)
    rgb = cv2.pyrDown(large)
    gray = cv2.cvtColor(rgb, cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray, 3)

    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))
    grad = cv2.morphologyEx(gray, cv2.MORPH_GRADIENT, kernel)

    _, bw = cv2.threshold(grad, 0.0, 255.0, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 1))
    connected = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, kernel)

    contours, _ = cv2.findContours(connected.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    six_y = None
    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        if w < 5 or h < 10:
            continue

        pad_w, pad_h = 2, 2
        x_pad = max(x - pad_w, 0)
        y_pad = max(y - pad_h, 0)
        w_pad = min(w + pad_w * 2, rgb.shape[1] - x_pad)
        h_pad = min(h + pad_h * 2, rgb.shape[0] - y_pad)

        roi = gray[y_pad:y_pad + h_pad, x_pad:x_pad + w_pad]
        roi_resized = cv2.resize(roi, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)
        text = pytesseract.image_to_string(roi_resized, config='--psm 10 -c tessedit_char_whitelist=0123456789').strip()

        if re.fullmatch(r'\d', text) and text == '6':
            six_y = y_pad

    if six_y is not None:
        cutoff_y = six_y + 80
        cropped = rgb[:cutoff_y, :]
    else:
        cropped = rgb

    resized = cv2.resize(cropped, (787, 1420), interpolation=cv2.INTER_AREA)
    return resized

def is_cell_free(region):
    # ë¹„ì–´ìˆëŠ” ì…€: ê±°ì˜ ê²€ì • ë˜ëŠ” í°ìƒ‰ë§Œ ìˆëŠ” ì…€ë¡œ ê°„ì£¼
    region = region.astype(np.int16)
    black_mask = np.linalg.norm(region - [17, 17, 17], axis=2) < 40
    white_mask = np.linalg.norm(region - [255, 255, 255], axis=2) < 40
    free_ratio = (black_mask | white_mask).sum() / (region.shape[0] * region.shape[1])
    return free_ratio > 0.7

def find_common_free_slots(img1, img2, start_x=40, start_y=36, end_x=787, end_y=1420, rows=10, cols=5):
    cell_height = (end_y - start_y) // rows
    cell_width = (end_x - start_x) // cols

    for row in range(rows):
        for col in range(cols):
            y1 = start_y + row * cell_height
            y2 = y1 + cell_height
            x1 = start_x + col * cell_width
            x2 = x1 + cell_width

            region1 = img1[y1:y2, x1:x2]
            region2 = img2[y1:y2, x1:x2]

            if is_cell_free(region1) and is_cell_free(region2):
                img1[y1:y2, x1:x2] = [0, 255, 255]  # ë…¸ë€ìƒ‰
                img2[y1:y2, x1:x2] = [0, 255, 255]

    return img1, img2

def change_background_based_on_color(img, start_x, start_y, end_x, end_y):
    """
    ë°°ê²½ ìƒ‰ìƒì„ (1,1) ìœ„ì¹˜ì˜ ìƒ‰ì— ë§ì¶”ì–´ (40, 36)ë¶€í„° (787, 1420) ì˜ì—­ì—ë§Œ ì ìš©í•˜ë©°, 
    í•˜ì´ë¼ì´íŠ¸ëœ ë¶€ë¶„ì€ ì œì™¸í•˜ê³  ìƒ‰ì„ ë°”ê¿‰ë‹ˆë‹¤.
    """
    # (1, 1) ìœ„ì¹˜ì—ì„œ ë°°ê²½ìƒ‰ì„ í™•ì¸
    if np.allclose(img[1, 1], [17, 17, 17]):  # ê²€ì€ìƒ‰ ë°°ê²½
        background_color = [17, 17, 17]
    elif np.allclose(img[1, 1], [255, 255, 255]):  # í°ìƒ‰ ë°°ê²½
        background_color = [255, 255, 255]
    else:
        return img  # ë°°ê²½ ìƒ‰ìƒì´ ê²€ì€ìƒ‰ì´ë‚˜ í°ìƒ‰ì´ ì•„ë‹Œ ê²½ìš° ë³€ê²½í•˜ì§€ ì•ŠìŒ

    # ë°°ê²½ ìƒ‰ìƒì„ ë³€ê²½
    for y in range(start_y, end_y):
        for x in range(start_x, end_x):
            if np.allclose(img[y, x], [0, 255, 255]):  # í•˜ì´ë¼ì´íŠ¸ëœ ë¶€ë¶„ì€ ì œì™¸
                continue
            img[y, x] = background_color
    return img
@app.post("/timetable", response_model=TimetableResponseDto)
async def highlight_timetables(images: List[UploadFile] = File(...)):
    try:
        # ì„ì‹œ ì €ì¥
        temp_paths = []
        for image in images:
            temp = NamedTemporaryFile(delete=False, suffix=".jpg")
            temp.write(await image.read())
            temp.close()
            temp_paths.append(temp.name)

        # ì´ë¯¸ì§€ ë¡œë”©
        img1 = cv2.imread(temp_paths[0])
        img2 = cv2.imread(temp_paths[1])

        if img1 is None or img2 is None:
            raise ValueError("ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. JPEG í˜•ì‹ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

        # ì „ì²˜ë¦¬ ë° ë¶„ì„
        processed1 = preprocess_and_resize(img1)
        processed2 = preprocess_and_resize(img2)
        highlighted, _ = find_common_free_slots(processed1.copy(), processed2.copy())

        # âœ… ë¶€ë“œëŸ¬ìš´ í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬ ì‹œì‘
        def apply_soft_highlight(base_img, highlighted_img, mask_color=(0, 255, 0), alpha=0.35):
            mask = cv2.inRange(highlighted_img, (0, 250, 0), (0, 255, 0))  # ì´ˆë¡ ë§ˆìŠ¤í¬
            result = base_img.copy()
            result[mask > 0] = (
                alpha * np.array(mask_color) + (1 - alpha) * result[mask > 0]
            ).astype(np.uint8)
            return result

        result_image = apply_soft_highlight(processed1, highlighted)

        # 6. ê²°ê³¼ ì €ì¥
        output_dir = "output"
        os.makedirs(output_dir, exist_ok=True)
        result_path = os.path.join(output_dir, f"highlighted_{images[0].filename}")
        cv2.imwrite(result_path, result_image)

        # 7. ê²°ê³¼ ë°˜í™˜
        return TimetableResponseDto(imageUrl=result_path)

    except Exception as e:
        return JSONResponse(status_code=400, content={"error": str(e)})
