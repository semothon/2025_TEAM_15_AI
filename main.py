from fastapi import FastAPI, UploadFile, File, Query, Form
from pydantic import BaseModel
from fastapi.responses import JSONResponse
from typing import List, Optional, Union
from openai import OpenAI
from dotenv import load_dotenv
import json
from utils.time.image_parser import get_schedule_mask
from utils.time.visualize import visualize_free_mask
from utils.grad.analyzer import analyze_graduation_pdf
from utils.grad.pdf_parser import parse_pdf
import numpy as np
from typing import Dict, Any
# í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
load_dotenv()
client = OpenAI()

# ê³¼ëª© ë°ì´í„° ë¡œë”©
with open("data/cse_course.json", "r", encoding="utf-8") as f:
    curriculum = json.load(f)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()

# ìš”ì²­ ëª¨ë¸
class RecommendRequest(BaseModel):
    keyword: str
    add_info: str

# ì¶”ì²œ í•­ëª© ëª¨ë¸
class RecommendationItem(BaseModel):
    title: str
    description: str

# ì‘ë‹µ ëª¨ë¸
class RecommendResponse(BaseModel):
    keyword: str
    add_info: str
    ai_response: str  # ë¬¸ìì—´ ì‘ë‹µìœ¼ë¡œ êµ¬ì„±

# ì—ëŸ¬ ì‘ë‹µ ëª¨ë¸
class ErrorResponse(BaseModel):
    error: str
    raw_text: Optional[str] = None
    warning: Optional[str] = None

class ChatRequest(BaseModel):
    question: str

class ChatResponse(BaseModel):
    question: str
    ai_add_response: str

##### ê³¼ëª© ì¶”ì²œ #####
@app.post("/recommend", response_model=Union[RecommendResponse, ErrorResponse])
async def recommend(request: RecommendRequest):
    keyword = request.keyword.lower()

    # ê´€ë ¨ í‚¤ì›Œë“œ ê³¼ëª© í•„í„°ë§
    related = [c for c in curriculum if keyword in [k.lower() for k in c.get("keywords", [])]]
    samples = related[:5] if related else curriculum[:5]

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    context_text = "\n".join([
        f"- {c['name']} ({c['category']}, {c['credit']}í•™ì ): {c.get('description', 'ì„¤ëª… ì—†ìŒ')}"
        for c in samples
    ])

    prompt = f"""
    ë„ˆëŠ” ëŒ€í•™ìƒì—ê²Œ ê³¼ëª©ì„ ì¶”ì²œí•´ì£¼ëŠ” AI ì¡°êµì•¼.
    ì•„ë˜ ì‚¬ìš©ì ì •ë³´ì™€ ê³¼ëª© ëª©ë¡ì„ ì°¸ê³ í•´ì„œ 3ê°œ ê³¼ëª©ì„ ì¶”ì²œí•´ì¤˜.
    ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´:

    {{
    "recommendations": [
        {{
        "title": "ê³¼ëª©ëª…",
        "description": "ì„¤ëª…"
        }},
        ...
    ]
    }}

ğŸ” ê´€ì‹¬ ë¶„ì•¼: {request.keyword}
â„¹ï¸ ì¶”ê°€ ì •ë³´: {request.add_info}
ê³¼ëª© ëª©ë¡:
{context_text}
    """

    try:
        # OpenAI API í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” AI ì¡°êµì•¼. ë°˜ë“œì‹œ JSONë§Œìœ¼ë¡œ ë‹µë³€í•´."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4
        )

        result_raw = response.choices[0].message.content.strip()
        print("ğŸ§  AI ì‘ë‹µ ì›ë¬¸:\n", result_raw)

        result_json = json.loads(result_raw)
        recommendations = result_json.get("recommendations", [])

        # ë¬¸ìì—´ë¡œ ì‘ë‹µ í¬ë§·íŒ…
        formatted_response = "\n".join([
            f"{i+1}. {r['title']} - {r['description']}" for i, r in enumerate(recommendations)
        ])

        return RecommendResponse(
            keyword=request.keyword,
            add_info=request.add_info,
            ai_response=formatted_response
        )

    except json.JSONDecodeError:
        return ErrorResponse(
            error="JSON íŒŒì‹± ì‹¤íŒ¨",
            raw_text=result_raw,
            warning="AI ì‘ë‹µì„ JSONìœ¼ë¡œ ë³€í™˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        )

    except Exception as e:
        return ErrorResponse(error=str(e))

##### ì§ˆì˜ì‘ë‹µ #####
conversation_history = []
@app.post("/chat", response_model=ChatResponse)
async def chat(req: ChatRequest):
    question = req.question.strip()

    # ê³¼ëª© ë°ì´í„° ìš”ì•½ (ìµœëŒ€ 100ê°œë§Œ)
    summarized = "\n".join([
        f"[{c['code'] or 'N/A'}] {c['name']} | {c['category']}, {c['credit']}í•™ì , {c['year']}í•™ë…„ | í‚¤ì›Œë“œ: {', '.join(c.get('keywords', []))}\nì„¤ëª…: {c.get('description', 'ì„¤ëª… ì—†ìŒ')}"
        for c in curriculum[:1000]
    ])

    # AI ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    system_prompt = """
    ë„ˆëŠ” ê²½í¬ëŒ€ ì»´í“¨í„°ê³µí•™ê³¼ GPT ì¡°êµì•¼.
    í•™ìƒì´ ì»¤ë¦¬í˜ëŸ¼ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•˜ë©´ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µí•´ì¤˜.
    ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì •ë³´ëŠ” "ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë§í•´.
    """

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì§ˆë¬¸ ì¶”ê°€
    conversation_history.append({"role": "user", "content": question})

    try:
        # OpenAI API í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": summarized}
            ] + conversation_history,
            temperature=0.4
        )

        reply = response.choices[0].message.content.strip()
        conversation_history.append({"role": "assistant", "content": reply})

        # ChatResponse í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ
        return ChatResponse(
            question=question,
            ai_add_response=reply
        )

    except Exception as e:
        return JSONResponse(
            content={"error": str(e)},
            status_code=500
        )

import os
import shutil

class AnalyzePdfResponse(BaseModel):
    responseData: Dict[str, Any]

@app.post("/analyze-pdf", response_model=AnalyzePdfResponse)
async def analyze_pdf(
    file: UploadFile = File(..., description="ì¡¸ì—… ì§„ë‹¨í‘œ PDF íŒŒì¼"),
    department: str = Form(..., description="í•™ê³¼ëª…"),
    studentId: str = Form(..., description="í•™ë²ˆ")
):
    try:
        # 1. íŒŒì¼ í˜•ì‹ í™•ì¸
        if file.content_type != "application/pdf":
            return AnalyzePdfResponse(responseData={
                "error": "PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
                "fileName": file.filename
            })

        # 2. íŒŒì¼ ë‚´ìš© ì½ê¸°
        content = await file.read()

        # 3. ì¡¸ì—… ì§„ë‹¨ ì‹¤í–‰
        result = await analyze_graduation_pdf(content, department, studentId)

        # 4. ë¶„ì„ ê²°ê³¼ ê°ì‹¸ê¸°
        if isinstance(result, dict):
            analysis_result = result
        else:
            analysis_result = {"result": result}

        # 5. ê³µí†µ ë©”íƒ€ ì •ë³´ + ë¶„ì„ ê²°ê³¼ í¬í•¨
        return AnalyzePdfResponse(responseData={
            "studentId": studentId,
            "department": department,
            "fileName": file.filename,
            "message": "FastAPI ì—…ë¡œë“œ ë° ì¡¸ì—… ì§„ë‹¨ ì„±ê³µ âœ…",
            "analysis": analysis_result
        })

    except Exception as e:
        return AnalyzePdfResponse(responseData={
            "error": f"ì„œë²„ ì˜¤ë¥˜: {str(e)}"
        })
##### ê³µê°• ì‹œê°„í‘œ #####

import cv2
import numpy as np
import pytesseract
import re
import os
from fastapi import FastAPI, UploadFile, File
from fastapi.responses import FileResponse
from tempfile import NamedTemporaryFile
pytesseract.pytesseract.tesseract_cmd = "/opt/homebrew/bin/tesseract"

# âœ… ì „ì²˜ë¦¬ í•¨ìˆ˜: í¬ê¸° ì¡°ì ˆ + ROI ì¶”ì¶œ
def preprocess_and_resize(img):
    large = cv2.resize(img, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_CUBIC)
    rgb = cv2.pyrDown(large)
    gray = cv2.cvtColor(rgb, cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray, 3)

    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))
    grad = cv2.morphologyEx(gray, cv2.MORPH_GRADIENT, kernel)
    _, bw = cv2.threshold(grad, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    connected = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT, (2, 1)))

    contours, _ = cv2.findContours(connected.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    six_y = None
    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        if w < 5 or h < 10:
            continue

        pad = 2
        x_pad = max(x - pad, 0)
        y_pad = max(y - pad, 0)
        w_pad = min(w + pad * 2, rgb.shape[1] - x_pad)
        h_pad = min(h + pad * 2, rgb.shape[0] - y_pad)

        roi = gray[y_pad:y_pad + h_pad, x_pad:x_pad + w_pad]
        roi_resized = cv2.resize(roi, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)
        text = pytesseract.image_to_string(roi_resized, config='--psm 10 -c tessedit_char_whitelist=0123456789').strip()

        if text == '6':
            six_y = y_pad

    cutoff_y = six_y + 80 if six_y is not None else rgb.shape[0]
    cropped = rgb[:cutoff_y, :]
    resized = cv2.resize(cropped, (787, 1420), interpolation=cv2.INTER_AREA)
    return resized

# âœ… ê³µí†µ ê³µê°• ë§ˆìŠ¤í¬ ìƒì„± ë° í•˜ì´ë¼ì´íŒ…
def find_common_free_slots(img1, img2, start_x=40, start_y=36, end_x=787, end_y=1420):
    region1 = img1[start_y:end_y, start_x:end_x]
    region2 = img2[start_y:end_y, start_x:end_x]

    # ë¹„ì–´ìˆëŠ” ì‹œê°„ = ë°ì€ ìƒ‰ (í°ìƒ‰ or íšŒìƒ‰ ê³„ì—´)
    mask1 = ((region1 == [17, 17, 17]).all(axis=2)) | ((region1 == [255, 255, 255]).all(axis=2))
    mask2 = ((region2 == [17, 17, 17]).all(axis=2)) | ((region2 == [255, 255, 255]).all(axis=2))
    common_mask = mask1 & mask2

    region1[common_mask] = [0, 255, 255]  # ë…¸ë€ìƒ‰ìœ¼ë¡œ ê³µê°• í‘œì‹œ
    region2[common_mask] = [0, 255, 255]

    img1[start_y:end_y, start_x:end_x] = region1
    img2[start_y:end_y, start_x:end_x] = region2
    return img1, img2

# âœ… FastAPI ì—”ë“œí¬ì¸íŠ¸
@app.post("/timetable")
async def highlight_timetables(
    file1: UploadFile = File(...),
    file2: UploadFile = File(...)
):
    try:
        # 1. ì„ì‹œ íŒŒì¼ ì €ì¥
        temp1 = NamedTemporaryFile(delete=False, suffix=".jpg")
        temp2 = NamedTemporaryFile(delete=False, suffix=".jpg")
        temp1.write(await file1.read())
        temp2.write(await file2.read())
        temp1.close()
        temp2.close()

        # 2. ì´ë¯¸ì§€ ë¡œë”©
        img1 = cv2.imread(temp1.name)
        img2 = cv2.imread(temp2.name)

        if img1 is None or img2 is None:
            return JSONResponse(status_code=400, content={
                "resultCode": "ERROR",
                "message": "ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨. JPEG í˜•ì‹ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.",
                "data": None
            })

        # 3. ì „ì²˜ë¦¬ ë° ê³µê°• ë¶„ì„
        processed1 = preprocess_and_resize(img1)
        processed2 = preprocess_and_resize(img2)
        highlighted1, highlighted2 = find_common_free_slots(processed1.copy(), processed2.copy())

        # 4. ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        result_dir = "output"
        os.makedirs(result_dir, exist_ok=True)

        # 5. ì €ì¥ ê²½ë¡œ ìƒì„±
        out_path1 = os.path.join(result_dir, f"highlighted_{file1.filename}")
        out_path2 = os.path.join(result_dir, f"highlighted_{file2.filename}")

        cv2.imwrite(out_path1, highlighted1)
        cv2.imwrite(out_path2, highlighted2)

        # 6. ìŠ¤í”„ë§ì— ë§ëŠ” ì‘ë‹µ êµ¬ì¡°
        return {
            "resultCode": "SUCCESS",
            "message": "ê³µí†µ ê³µê°• ì‹œê°í™” ì™„ë£Œ",
            "data": {
                "highlightedTimetable1": out_path1,
                "highlightedTimetable2": out_path2
            }
        }

    except Exception as e:
        return JSONResponse(status_code=500, content={
            "resultCode": "ERROR",
            "message": f"FastAPI ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
            "data": None
        })
