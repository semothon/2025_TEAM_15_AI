# AI/evaluator/llm_evaluator.py

import os
from openai import OpenAI
import json
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def evaluate_with_llm(student_json: dict, graduation_rules: dict) -> str:
    system_prompt = (
        "ë„ˆëŠ” ëŒ€í•™êµ ì¡¸ì—… ìš”ê±´ í‰ê°€ ì‹œìŠ¤í…œì´ë‹¤. "
        "ì…ë ¥ëœ ì¡¸ì—… ìš”ê±´ê³¼ í•™ìƒì˜ ì´ìˆ˜ í˜„í™©ì„ ë¹„êµí•˜ì—¬ ì¡¸ì—… ê°€ëŠ¥ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê³ , "
        "ë¶€ì¡±í•œ í•­ëª©ì´ ìˆë‹¤ë©´ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜. ë§ˆì§€ë§‰ì— ì¡°ì¹˜ì‚¬í•­ë„ ì¶”ì²œí•´ì¤˜.\n"
        "ì‘ë‹µì€ ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¼ì•¼ í•œë‹¤:\n"
        "- ì¡¸ì—… ê°€ëŠ¥ ì—¬ë¶€\n"
        "- ë¶€ì¡± í•­ëª©ë“¤\n"
        "- ğŸ‘‰ ì¡°ì¹˜ì‚¬í•­"
    )

    user_input = {
        "student": student_json,
        "rules": graduation_rules
    }

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": str(user_input)}
            ],
            temperature=0.3
        )
        print("ğŸ” GPTë¡œ ì „ë‹¬í•˜ëŠ” student_json â†“â†“â†“")
        print(json.dumps(student_json, ensure_ascii=False, indent=2))
        print("ğŸ” GPTë¡œ ì „ë‹¬í•˜ëŠ” graduation_rules â†“â†“â†“")
        print(json.dumps(graduation_rules, ensure_ascii=False, indent=2))

        result = response.choices[0].message.content
        print("ğŸ§  GPT ì‘ë‹µ â†“â†“â†“\n", result)
        return result
        

    except Exception as e:
        print(f"ğŸ”¥ GPT í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return f"LLM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
